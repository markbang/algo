{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_excel(\"副本工作簿1.xlsx\", sheet_name=\"111 \")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "# 函数：从Excel文件中提取期刊名称\n",
    "def extract_journals_from_excel(file_path):\n",
    "    try:\n",
    "        df = pd.read_excel(file_path, sheet_name=\"111 \")  # 读取Excel文件\n",
    "        if \"SO\" not in df.columns:\n",
    "            print(\"Excel文件中未找到'SO'字段，请检查文件！\")\n",
    "            return []\n",
    "        journals = df[\"SO\"].dropna().tolist()  # 提取'SO'字段并去掉空值\n",
    "        return journals\n",
    "    except Exception as e:\n",
    "        print(f\"读取Excel文件时出错: {e}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "# 函数：分析布拉德福定律\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import linregress\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def analyze_bradford(file_path):\n",
    "    # 提取期刊数据（你已有的函数）\n",
    "    journals = extract_journals_from_excel(file_path)\n",
    "    if not journals:\n",
    "        print(\"未找到期刊数据，请检查文件！\")\n",
    "        return\n",
    "\n",
    "    # 统计每种期刊的文章数量\n",
    "    journal_counts = Counter(journals)\n",
    "\n",
    "    # 按文章数量降序排序\n",
    "    sorted_journals = sorted(journal_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 计算排名 n 和累积文章数 R(n)\n",
    "    n = np.arange(1, len(sorted_journals) + 1)\n",
    "    R_n = np.cumsum([count for _, count in sorted_journals])\n",
    "\n",
    "    # 计算 ln(n)\n",
    "    ln_n = np.log(n)\n",
    "\n",
    "    # 线性回归\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(ln_n, R_n)\n",
    "    regression_line = slope * ln_n + intercept\n",
    "\n",
    "    # ---------------- 下面是可视化的改进示例 ----------------\n",
    "    # 1. 使用 seaborn 风格\n",
    "    sns.set_style(\"whitegrid\")  # 也可选择 'darkgrid', 'white', 'ticks' 等\n",
    "\n",
    "    # 2. 设置中文字体（如果你的系统支持 'SimHei'）\n",
    "    plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "    plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "\n",
    "    # 3. 创建图表\n",
    "    fig, ax = plt.subplots(figsize=(9, 6), dpi=100)\n",
    "\n",
    "    # 4. 绘制散点图\n",
    "    #   - 调整散点大小 (s) 和透明度 (alpha) 来突出或弱化数据点\n",
    "    ax.scatter(\n",
    "        ln_n, R_n, color=\"blue\", edgecolor=\"white\", s=60, alpha=0.8, label=\"数据点\"\n",
    "    )\n",
    "\n",
    "    # 5. 绘制线性拟合线\n",
    "    #   - 调整线条宽度 (linewidth) 和样式 (linestyle)\n",
    "    ax.plot(\n",
    "        ln_n,\n",
    "        regression_line,\n",
    "        color=\"red\",\n",
    "        linewidth=2.0,\n",
    "        linestyle=\"-\",\n",
    "        label=f\"线性拟合: $R^2={r_value**2:.2f}$\",\n",
    "    )\n",
    "\n",
    "    # 6. 标题与坐标轴\n",
    "    #   - 可以考虑添加副标题或解释\n",
    "    ax.set_title(\"布拉德福定律分析\", fontsize=16, fontweight=\"bold\", pad=15)\n",
    "    ax.set_xlabel(\"ln(n)\", fontsize=12, labelpad=10)\n",
    "    ax.set_ylabel(\"R(n)\", fontsize=12, labelpad=10)\n",
    "\n",
    "    # 7. 网格线与背景\n",
    "    #   - 已通过 seaborn 的 whitegrid 风格启用网格\n",
    "    #   - 如果需要进一步定制网格线：\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "\n",
    "    # 8. 美化坐标刻度\n",
    "    #   - 可以根据数据范围选择合适的刻度步长\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=11)\n",
    "\n",
    "    # 9. 添加图例\n",
    "    ax.legend(loc=\"upper left\", frameon=True, fontsize=11)\n",
    "\n",
    "    # 10. 使布局自适应，避免文字与边缘重叠\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # 11. 显示图表\n",
    "    plt.show()\n",
    "\n",
    "    # ---------------- 分割线：回到分析逻辑的输出 ----------------\n",
    "    print(f\"线性回归的R²值: {r_value**2:.2f}\")\n",
    "    if r_value**2 > 0.9:\n",
    "        print(\"数据符合布拉德福定律。\")\n",
    "        N = sum(journal_counts.values())\n",
    "        target = N / 3  # 基于三区划分计算核心期刊\n",
    "        core_journals = next(i for i, cumsum in enumerate(R_n, 1) if cumsum >= target)\n",
    "        print(f\"总文章数: {N}\")\n",
    "        print(f\"核心期刊数量: {core_journals}\")\n",
    "    else:\n",
    "        print(\"数据不符合布拉德福定律。可能是数据量不足或分布不均匀。\")\n",
    "\n",
    "\n",
    "# 使用示例\n",
    "analyze_bradford(\"副本工作簿1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "\n",
    "# 函数：分析齐普夫定律\n",
    "def analyze_zipf(file_path):\n",
    "    \"\"\"分析期刊数据是否符合齐普夫定律，并计算参数 C\"\"\"\n",
    "    # 提取期刊数据\n",
    "    journals = extract_journals_from_excel(file_path)\n",
    "    if not journals:\n",
    "        print(\"未找到期刊数据，请检查文件！\")\n",
    "        return\n",
    "\n",
    "    # 统计每种期刊的文章数量\n",
    "    journal_counts = Counter(journals)\n",
    "\n",
    "    # 按文章数量降序排序\n",
    "    sorted_journals = sorted(journal_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # 提取排名 r 和文章数量 f(r)\n",
    "    r = np.arange(1, len(sorted_journals) + 1)  # 排名从1开始\n",
    "    f_r = np.array([count for _, count in sorted_journals])  # 文章数量\n",
    "\n",
    "    # 计算 log(r) 和 log(f(r))\n",
    "    log_r = np.log(r)\n",
    "    log_f_r = np.log(f_r)\n",
    "\n",
    "    # 进行线性回归\n",
    "    slope, intercept, r_value, p_value, std_err = linregress(log_r, log_f_r)\n",
    "    k = -slope  # 齐普夫定律中 k = -slope\n",
    "    C = np.exp(intercept)  # C = e^{intercept}\n",
    "\n",
    "    # 绘制 log(r) vs log(f(r)) 的散点图和拟合直线\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(log_r, log_f_r, color=\"blue\", label=\"数据点\")\n",
    "    plt.plot(\n",
    "        log_r,\n",
    "        slope * log_r + intercept,\n",
    "        color=\"red\",\n",
    "        label=f\"线性拟合: R²={r_value**2:.2f}\",\n",
    "    )\n",
    "    plt.xlabel(\"log(r)\")\n",
    "    plt.ylabel(\"log(f(r))\")\n",
    "    plt.title(\"齐普夫定律分析\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # 输出分析结果\n",
    "    print(f\"线性回归的R²值: {r_value**2:.2f}\")\n",
    "    print(f\"参数 k: {k:.2f}\")\n",
    "    print(f\"参数 C: {C:.2f}\")\n",
    "\n",
    "    # 判断是否符合齐普夫定律\n",
    "    if r_value**2 > 0.9:\n",
    "        print(\"数据符合齐普夫定律。\")\n",
    "    else:\n",
    "        print(\"数据不符合齐普夫定律。可能是数据量不足或分布不均匀。\")\n",
    "\n",
    "\n",
    "# 使用示例：分析名为 'journal_data.xlsx' 的Excel文件\n",
    "analyze_zipf(\"副本工作簿1.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import linregress\n",
    "\n",
    "# 读取 Excel 文件，注意工作表名称和字段名\n",
    "file_path = \"副本工作簿1.xlsx\"\n",
    "sheet_name = \"111 \"\n",
    "\n",
    "try:\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "except Exception as e:\n",
    "    print(\"读取文件出错:\", e)\n",
    "    raise\n",
    "\n",
    "# 检查是否存在 'SO' 字段\n",
    "if \"SO\" not in df.columns:\n",
    "    raise ValueError(\"数据中没有找到 'SO' 字段，请检查数据。\")\n",
    "\n",
    "# 统计每个期刊的文章数量\n",
    "journal_counts = df[\"SO\"].value_counts()\n",
    "\n",
    "# 构造频次分布：发表x篇文章的期刊数量\n",
    "freq_distribution = journal_counts.value_counts().sort_index()\n",
    "\n",
    "# 如果频次分布数据点少于2个，无法进行回归分析\n",
    "if len(freq_distribution) < 2:\n",
    "    raise ValueError(\"数据点不足，无法进行回归分析。\")\n",
    "\n",
    "# 准备对数转换数据\n",
    "x = np.array(freq_distribution.index, dtype=float)\n",
    "y = np.array(freq_distribution.values, dtype=float)\n",
    "\n",
    "log_x = np.log(x)\n",
    "log_y = np.log(y)\n",
    "\n",
    "# 线性回归拟合： log(y) = log(C) - n*log(x)\n",
    "slope, intercept, r_value, p_value, std_err = linregress(log_x, log_y)\n",
    "\n",
    "C_value = np.exp(intercept)\n",
    "\n",
    "# 绘制对数-对数图\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(log_x, log_y, color=\"blue\", label=\"实际数据\")\n",
    "plt.plot(\n",
    "    log_x,\n",
    "    intercept + slope * log_x,\n",
    "    \"r-\",\n",
    "    label=f\"拟合直线: slope={slope:.2f}, intercept={intercept:.2f}\",\n",
    ")\n",
    "plt.xlabel(\"log(文章数 x)\")\n",
    "plt.ylabel(\"log(期刊数量 y)\")\n",
    "plt.title(\"期刊数据对数-对数图及洛特卡定律拟合\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"lotka_fit.png\")\n",
    "plt.show()\n",
    "\n",
    "print(\"通过图像法验证，期刊数据近似符合洛特卡定律。\")\n",
    "print(\"参数 C 的值为：\", C_value)\n",
    "print(\"拟合直线的斜率（-n）为：\", slope)\n",
    "print(\"拟合优度 R² 为：\", r_value**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 读取Excel文件（请确保文件路径正确）\n",
    "file_path = \"副本工作簿1.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"111 \")\n",
    "\n",
    "# 提取作者字段（假设作者列名为 'AU'，请根据实际列名调整）\n",
    "authors = df[\"AU\"].dropna().tolist()\n",
    "\n",
    "# 统计每个作者的发文量\n",
    "author_counts = defaultdict(int)\n",
    "for entry in authors:\n",
    "    # 拆分多个作者（假设用分号分隔）\n",
    "    for author in entry.split(\";\"):\n",
    "        author = author.strip()\n",
    "        author_counts[author] += 1\n",
    "\n",
    "# 生成发文量频次表\n",
    "x_values = []\n",
    "y_values = []\n",
    "for count in author_counts.values():\n",
    "    x_values.append(count)\n",
    "\n",
    "# 统计每个x对应的Y（作者数量）\n",
    "freq = defaultdict(int)\n",
    "for x in x_values:\n",
    "    freq[x] += 1\n",
    "\n",
    "# 提取x和Y\n",
    "x = np.array(list(freq.keys()))\n",
    "Y = np.array(list(freq.values()))\n",
    "\n",
    "# 对数转换（过滤x=0以避免log(0)）\n",
    "valid_indices = (x > 0) & (Y > 0)\n",
    "x_log = np.log(x[valid_indices]).reshape(-1, 1)\n",
    "Y_log = np.log(Y[valid_indices])\n",
    "\n",
    "# 线性回归\n",
    "model = LinearRegression().fit(x_log, Y_log)\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "C = np.exp(intercept)\n",
    "\n",
    "# 绘制双对数散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(x_log, Y_log, color=\"blue\", label=\"Data Points\")\n",
    "plt.plot(\n",
    "    x_log,\n",
    "    model.predict(x_log),\n",
    "    color=\"red\",\n",
    "    label=f\"Fit: y = {slope:.2f}x + {intercept:.2f}\",\n",
    ")\n",
    "plt.xlabel(\"ln(x) (发文量)\")\n",
    "plt.ylabel(\"ln(Y) (作者数量)\")\n",
    "plt.title(\"洛特卡定律验证（双对数坐标）\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 输出结果\n",
    "print(f\"回归斜率: {slope:.4f}（应接近 -2）\")\n",
    "print(f\"回归截距: {intercept:.4f}\")\n",
    "print(f\"参数 C = e^{intercept:.4f} ≈ {C:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# 读取Excel文件（请确保文件路径正确）\n",
    "file_path = \"副本工作簿1.xlsx\"\n",
    "df = pd.read_excel(file_path, sheet_name=\"111 \")\n",
    "\n",
    "# 提取期刊名称字段（假设列名为 'SO'，请根据实际调整）\n",
    "journals = df[\"SO\"].dropna().tolist()\n",
    "\n",
    "# 统计每个期刊的发文量\n",
    "journal_counts = defaultdict(int)\n",
    "for journal in journals:\n",
    "    journal = journal.strip()\n",
    "    journal_counts[journal] += 1\n",
    "\n",
    "# 按发文量降序排序并分配排名\n",
    "sorted_journals = sorted(journal_counts.items(), key=lambda x: -x[1])\n",
    "ranks = np.arange(1, len(sorted_journals) + 1)\n",
    "counts = np.array([count for _, count in sorted_journals])\n",
    "\n",
    "# 对数转换（过滤0值）\n",
    "valid_mask = (counts > 0) & (ranks > 0)\n",
    "log_ranks = np.log(ranks[valid_mask]).reshape(-1, 1)\n",
    "log_counts = np.log(counts[valid_mask])\n",
    "\n",
    "# 线性回归\n",
    "model = LinearRegression().fit(log_ranks, log_counts)\n",
    "slope = model.coef_[0]\n",
    "intercept = model.intercept_\n",
    "C = np.exp(intercept)\n",
    "\n",
    "# 绘制双对数散点图\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(log_ranks, log_counts, color=\"blue\", label=\"Data Points\")\n",
    "plt.plot(\n",
    "    log_ranks,\n",
    "    model.predict(log_ranks),\n",
    "    color=\"red\",\n",
    "    label=f\"Fit: y = {slope:.2f}x + {intercept:.2f}\",\n",
    ")\n",
    "plt.xlabel(\"ln(排名 r)\")\n",
    "plt.ylabel(\"ln(发文量 x)\")\n",
    "plt.title(\"齐普夫定律验证（双对数坐标）\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 输出结果\n",
    "print(f\"回归斜率: {slope:.4f}（应接近 -1）\")\n",
    "print(f\"回归截距: {intercept:.4f}\")\n",
    "print(f\"参数 C = e^{intercept:.4f} ≈ {C:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "len(data[\"CR\"].head(1).values[0].split(\";\"))\n",
    "# 计算引文率 = 引用次数 / 文章总数\n",
    "cited_list = []\n",
    "for citations in data[\"CR\"]:\n",
    "    if pd.notnull(citations):\n",
    "        cited_list.extend(citations.split(\";\"))\n",
    "cited_count = len(set(cited_list))\n",
    "citation_rate = cited_count / len(data)\n",
    "print(f\"引文率: {citation_rate:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "\"\"\"被引量最高的5本期刊中的：\n",
    "期刊字段是JA，引文字段是CR,参考上面\n",
    "（1）期刊被引量\n",
    "\n",
    "（2）平均被引率\n",
    "\n",
    "（3）2020年的影响因子\n",
    "\n",
    "（4）2020年的当年指标\"\"\"\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 解析CR字段，提取被引年份和期刊\n",
    "def parse_cr(cr_str):\n",
    "    # Check if cr_str is NaN or not a string\n",
    "    if pd.isna(cr_str) or not isinstance(cr_str, str):\n",
    "        return []  # Return empty list for invalid input\n",
    "    # Proceed with splitting if it's a valid string\n",
    "    citations = cr_str.split(\";\")\n",
    "    result = []\n",
    "    for citation in citations:\n",
    "        parts = [part.strip() for part in citation.split(\",\")]\n",
    "        if len(parts) >= 3:\n",
    "            try:\n",
    "                year = int(parts[1])  # Convert year to integer\n",
    "                journal = parts[2]  # Extract journal name\n",
    "                result.append((year, journal))\n",
    "            except ValueError:\n",
    "                continue  # Skip if year conversion fails\n",
    "    return result\n",
    "\n",
    "\n",
    "# 统计被引量\n",
    "cited_journal_counter = Counter()\n",
    "for index, row in data.iterrows():\n",
    "    citations = parse_cr(row[\"CR\"])\n",
    "    for cited_year, cited_journal in citations:\n",
    "        cited_journal_counter[cited_journal] += 1\n",
    "\n",
    "# 确定Top 5期刊\n",
    "top_5_journals = [journal for journal, count in cited_journal_counter.most_common(5)]\n",
    "\n",
    "# 计算发表文章数\n",
    "publication_counts = data.groupby([\"SO\", \"PY\"]).size().unstack(fill_value=0)\n",
    "# 统计2020年文章对2018、2019、2020年文章的引用\n",
    "citations_2020_to_2018 = Counter()\n",
    "citations_2020_to_2019 = Counter()\n",
    "citations_2020_to_2020 = Counter()\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    article_year = row[\"PY\"]\n",
    "    citations = parse_cr(row[\"CR\"])\n",
    "    if article_year == 2022:\n",
    "        for cited_year, cited_journal in citations:\n",
    "            if cited_year == 2020:\n",
    "                citations_2020_to_2018[cited_journal] += 1\n",
    "            elif cited_year == 2021:\n",
    "                citations_2020_to_2019[cited_journal] += 1\n",
    "            elif cited_year == 2022:\n",
    "                citations_2020_to_2020[cited_journal] += 1\n",
    "print(citations_2020_to_2018)\n",
    "print(citations_2020_to_2019)\n",
    "print(citations_2020_to_2020)\n",
    "# 计算并输出指标\n",
    "for journal in top_5_journals:\n",
    "    print(journal)\n",
    "    cited_count = cited_journal_counter[journal]\n",
    "    for i in publication_counts.index:\n",
    "        print(i)\n",
    "        if journal in i:\n",
    "            pub_total = publication_counts.loc[i, 2022]\n",
    "            print(pub_total)\n",
    "    print(f\"Publication Total: {pub_total}, Cited Count: {cited_count}\")\n",
    "    # 平均被引率\n",
    "    if pub_total > 0:\n",
    "        avg_citation_rate = cited_count / pub_total\n",
    "    else:\n",
    "        avg_citation_rate = np.nan\n",
    "\n",
    "    # 2020年影响因子\n",
    "    if journal in publication_counts.index:\n",
    "        pub_2018_2019 = (\n",
    "            publication_counts.loc[journal, 2020]\n",
    "            + publication_counts.loc[journal, 2021]\n",
    "        )\n",
    "        if pub_2018_2019 > 0:\n",
    "            impact_factor_2020 = (\n",
    "                citations_2020_to_2018[journal] + citations_2020_to_2019[journal]\n",
    "            ) / pub_2018_2019\n",
    "        else:\n",
    "            impact_factor_2020 = np.nan\n",
    "    else:\n",
    "        impact_factor_2020 = np.nan\n",
    "\n",
    "    # 2020年当年指标\n",
    "    if journal in publication_counts.index and 2022 in publication_counts.columns:\n",
    "        pub_2020 = publication_counts.loc[journal, 2022]\n",
    "        print(pub_2020)\n",
    "        if pub_2020 > 0:\n",
    "            immediacy_index_2020 = citations_2020_to_2020[journal] / pub_2020\n",
    "        else:\n",
    "            immediacy_index_2020 = np.nan\n",
    "    else:\n",
    "        immediacy_index_2020 = 0\n",
    "\n",
    "    # 使用print输出结果\n",
    "    print(f\"期刊: {journal}\")\n",
    "    print(f\"  被引量: {cited_count}\")\n",
    "    print(f\"  平均被引率: {avg_citation_rate:.2f}\")\n",
    "    print(f\"  2020年影响因子: {impact_factor_2020:.2f}\")\n",
    "    print(f\"  2020年当年指标: {immediacy_index_2020:.2f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 引文量字段是NR，期刊字段是SO\n",
    "# 总引文量分布如何\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data[\"NR\"].describe()\n",
    "# 总引文量分布（规律）如何？如何分析这一分布？\n",
    "\n",
    "data[\"NR\"].plot(\n",
    "    kind=\"hist\", bins=20, color=\"skyblue\", edgecolor=\"black\", figsize=(10, 6)\n",
    ")\n",
    "plt.rcParams[\"font.sans-serif\"] = [\"SimHei\"]\n",
    "plt.rcParams[\"axes.unicode_minus\"] = False\n",
    "plt.title(\"总引文量分布直方图\")\n",
    "plt.xlabel(\"总引文量\")\n",
    "plt.ylabel(\"频数\")\n",
    "plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# 找出引文最多几个的期刊\n",
    "top_journals = data.groupby(\"SO\")[\"NR\"].sum().nlargest(5)\n",
    "top_journals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
